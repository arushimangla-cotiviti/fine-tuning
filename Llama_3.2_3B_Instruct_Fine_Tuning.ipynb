{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c390680b-449f-4878-895b-0b47b9d8e7ea",
   "metadata": {},
   "source": [
    "# Installing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_state": "idle",
   "id": "02d9a4af-7873-420f-b451-546f993863fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_state": "idle",
   "id": "33056007-d700-43a7-95b7-836d2dd022eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"transformers\" \"datasets[s3]==2.13.0\" \"pandas>=2.0.0\" \"sagemaker>=2.190.0\" \"gradio==3.50.2\"  --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_state": "idle",
   "id": "3f8f4681-3ea6-4914-a3e8-a2332bb00a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (0.34.2)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (0.15.0)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (0.45.4)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.4.1.post300)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.49.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_state": "idle",
   "id": "de44e6ef-09ad-4341-928e-cb3359a7c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50985c03-9643-498d-8edf-e96213fc80f6",
   "metadata": {},
   "source": [
    "# Logging into Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_state": "idle",
   "id": "89fd9eeb-7ba6-4e02-87b6-27a05aa728c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `fine-tuning` has been saved to /home/sagemaker-user/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /home/sagemaker-user/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `fine-tuning`\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token \"xxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65cf7de-b307-40e9-98a2-c4f14b82a623",
   "metadata": {},
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_state": "idle",
   "id": "4b21fbb6-822b-4c27-b690-b47bb38fe504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 21:05:06.952262: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-27 21:05:07.215790: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-27 21:05:07.275781: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-27 21:05:07.293381: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-27 21:05:07.568516: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, pipeline\n",
    "from peft import LoraModel, get_peft_model, LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "\n",
    "pd.set_option('max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db60cb-a2ed-4b86-8163-14bd246f4fca",
   "metadata": {},
   "source": [
    "# Initializing Sagemaker Session and IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_state": "idle",
   "id": "a0909697-39dd-4b18-8bda-0e66f8a330ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::637423395717:role/service-role/AmazonSageMaker-ExecutionRole-20250324T120618\n",
      "sagemaker bucket: sagemaker-us-east-1-637423395717\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20250124T132142')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a51829-4d88-4126-a6cd-c079de6cac2f",
   "metadata": {},
   "source": [
    "# Getting Data from S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_state": "idle",
   "id": "ccbf1ed1-069e-4e55-b791-728ced350d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'sagemaker-bucket-fine-tuning'\n",
    "train_file_key = 'data_for_gdf_mapping.csv'  \n",
    "gdf_file_key = 'gdf_master_file.csv'\n",
    "\n",
    "response = s3.get_object(Bucket=bucket_name, Key=train_file_key)\n",
    "response_1 = s3.get_object(Bucket=bucket_name, Key=gdf_file_key)\n",
    "\n",
    "csv_content = response['Body'].read().decode('utf-8')\n",
    "csv_content_1 = response_1['Body'].read().decode('ISO-8859-1')\n",
    "train_data = pd.read_csv(StringIO(csv_content))\n",
    "gdf_master_data = pd.read_csv(StringIO(csv_content_1))           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7af46-d9ec-484c-b709-1943290bf40c",
   "metadata": {},
   "source": [
    "# Formatting Dataset into Instruction, Context and Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "execution_state": "idle",
   "id": "ca8d99d9-e394-40f1-a7a1-5ad086431c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           system_prompt  \\\n",
      "0                                                                         <|start_header_id|>system<|end_header_id|>\\nYou are an expert in mapping medical data fields. Your task is to map a raw field from a dataset to a GDF field, which is a standardized field used by our organization. You can use the raw field description and the GDF field description for context. Ensure you map the raw field to the appropriate GDF field accurately. Raw field: accountname. Raw field description: nan. GDF field: ch_group_name. GDF field description: The value in this field represents the name of the employer group that is tied to the employer group number..   \n",
      "1                              <|start_header_id|>system<|end_header_id|>\\nYou are an expert in mapping medical data fields. Your task is to map a raw field from a dataset to a GDF field, which is a standardized field used by our organization. You can use the raw field description and the GDF field description for context. Ensure you map the raw field to the appropriate GDF field accurately. Raw field: adjusment_reason_code. Raw field description: nan. GDF field: ch_adjustment_reason_code_02. GDF field description: This code communicates a reason for a payment adjustment that describes why the claim was paid differently than it was billed..   \n",
      "2  <|start_header_id|>system<|end_header_id|>\\nYou are an expert in mapping medical data fields. Your task is to map a raw field from a dataset to a GDF field, which is a standardized field used by our organization. You can use the raw field description and the GDF field description for context. Ensure you map the raw field to the appropriate GDF field accurately. Raw field: adjustment_reason_code. Raw field description: reason code for the adjustment. GDF field: ch_adjustment_reason_code_01. GDF field description: This code communicates a reason for a payment adjustment that describes why the claim was paid differently than it was billed..   \n",
      "3  <|start_header_id|>system<|end_header_id|>\\nYou are an expert in mapping medical data fields. Your task is to map a raw field from a dataset to a GDF field, which is a standardized field used by our organization. You can use the raw field description and the GDF field description for context. Ensure you map the raw field to the appropriate GDF field accurately. Raw field: adjustment_reason_code. Raw field description: reason code for the adjustment. GDF field: ch_adjustment_reason_code_03. GDF field description: This code communicates a reason for a payment adjustment that describes why the claim was paid differently than it was billed..   \n",
      "4  <|start_header_id|>system<|end_header_id|>\\nYou are an expert in mapping medical data fields. Your task is to map a raw field from a dataset to a GDF field, which is a standardized field used by our organization. You can use the raw field description and the GDF field description for context. Ensure you map the raw field to the appropriate GDF field accurately. Raw field: adjustment_reason_code. Raw field description: reason code for the adjustment. GDF field: ch_adjustment_reason_code_04. GDF field description: This code communicates a reason for a payment adjustment that describes why the claim was paid differently than it was billed..   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                          user_prompt  \\\n",
      "0                                                                         <|start_header_id|>user<|end_header_id|>\\nRaw field: accountname\\nRaw field description: nan\\nGDF field: ch_group_name\\nGDF field description: The value in this field represents the name of the employer group that is tied to the employer group number.   \n",
      "1                              <|start_header_id|>user<|end_header_id|>\\nRaw field: adjusment_reason_code\\nRaw field description: nan\\nGDF field: ch_adjustment_reason_code_02\\nGDF field description: This code communicates a reason for a payment adjustment that describes why the claim was paid differently than it was billed.   \n",
      "2  <|start_header_id|>user<|end_header_id|>\\nRaw field: adjustment_reason_code\\nRaw field description: reason code for the adjustment\\nGDF field: ch_adjustment_reason_code_01\\nGDF field description: This code communicates a reason for a payment adjustment that describes why the claim was paid differently than it was billed.   \n",
      "3  <|start_header_id|>user<|end_header_id|>\\nRaw field: adjustment_reason_code\\nRaw field description: reason code for the adjustment\\nGDF field: ch_adjustment_reason_code_03\\nGDF field description: This code communicates a reason for a payment adjustment that describes why the claim was paid differently than it was billed.   \n",
      "4  <|start_header_id|>user<|end_header_id|>\\nRaw field: adjustment_reason_code\\nRaw field description: reason code for the adjustment\\nGDF field: ch_adjustment_reason_code_04\\nGDF field description: This code communicates a reason for a payment adjustment that describes why the claim was paid differently than it was billed.   \n",
      "\n",
      "                                                                                                                response_prompt  \n",
      "0             <|start_header_id|>assistant<|end_header_id|>\\nCan you map the raw field 'accountname' to the correct GDF field?.  \n",
      "1   <|start_header_id|>assistant<|end_header_id|>\\nCan you map the raw field 'adjusment_reason_code' to the correct GDF field?.  \n",
      "2  <|start_header_id|>assistant<|end_header_id|>\\nCan you map the raw field 'adjustment_reason_code' to the correct GDF field?.  \n",
      "3  <|start_header_id|>assistant<|end_header_id|>\\nCan you map the raw field 'adjustment_reason_code' to the correct GDF field?.  \n",
      "4  <|start_header_id|>assistant<|end_header_id|>\\nCan you map the raw field 'adjustment_reason_code' to the correct GDF field?.  \n"
     ]
    }
   ],
   "source": [
    "# Clean column names by stripping whitespace and ensuring they're in lowercase\n",
    "train_data.columns = train_data.columns.str.lower().str.strip()        \n",
    "gdf_master_data.columns = gdf_master_data.columns.str.lower().str.strip()\n",
    "\n",
    "# Function to create instruction, context, and response in the required format\n",
    "def create_instructions(data_row, gdf_data):\n",
    "    raw_field = data_row['raw_field']\n",
    "    raw_desc = data_row['raw_desc']\n",
    "    gdf_field = data_row['gdf_field']\n",
    "\n",
    "    # Ensure consistent casing and strip extra spaces\n",
    "    raw_field = str(raw_field).lower().strip()\n",
    "    gdf_field = str(gdf_field).lower().strip()\n",
    "\n",
    "    # Get GDF description from the gdf_master_data based on the gdf_field\n",
    "    gdf_desc = gdf_data[gdf_data['gdf_field'].str.lower().str.strip() == gdf_field]['gdf_desc'].values\n",
    "\n",
    "    if len(gdf_desc) == 0:\n",
    "        gdf_desc = \"Description not found.\"\n",
    "    else:\n",
    "        gdf_desc = gdf_desc[0]  # In case there are multiple matches, take the first one.\n",
    "\n",
    "    # Construct the instruction\n",
    "    instruction = f\"You are an expert in mapping medical data fields. Your task is to map a raw field from a dataset to a GDF field, which is a standardized field used by our organization. You can use the raw field description and the GDF field description for context. Ensure you map the raw field to the appropriate GDF field accurately. Raw field: {raw_field}. Raw field description: {raw_desc}. GDF field: {gdf_field}. GDF field description: {gdf_desc}.\"\n",
    "\n",
    "    # Context: Provide both the raw description and GDF description for additional context\n",
    "    context = f\"Raw field: {raw_field}\\nRaw field description: {raw_desc}\\nGDF field: {gdf_field}\\nGDF field description: {gdf_desc}\"\n",
    "\n",
    "    # Response based on the structure you've shown\n",
    "    response = f\"Can you map the raw field '{raw_field}' to the correct GDF field?.\"\n",
    "\n",
    "    return {\n",
    "        'instruction': instruction,\n",
    "        'context': context,\n",
    "        'response': response\n",
    "    }\n",
    "\n",
    "# Apply the function row by row to create the instructions, context, and response\n",
    "formatted_data = train_data.apply(lambda row: create_instructions(row, gdf_master_data), axis=1)\n",
    "\n",
    "# Convert the result into a list of formatted data\n",
    "formatted_data_list = formatted_data.tolist()\n",
    "\n",
    "# Create a DataFrame from the formatted data\n",
    "formatted_df = pd.DataFrame(formatted_data_list)\n",
    "\n",
    "# Function to format for inference, providing the system prompt, user prompt, and response prompt\n",
    "def format_for_inference(row):\n",
    "    system_prompt = f\"<|start_header_id|>system<|end_header_id|>\\n{row['instruction']}\"\n",
    "    user_prompt = f\"<|start_header_id|>user<|end_header_id|>\\n{row['context']}\"\n",
    "    response_prompt = f\"<|start_header_id|>assistant<|end_header_id|>\\n{row['response']}\"\n",
    "\n",
    "    return {\n",
    "        'system_prompt': system_prompt,\n",
    "        'user_prompt': user_prompt,\n",
    "        'response_prompt': response_prompt\n",
    "    }\n",
    "\n",
    "# Apply the format_for_inference function to each row to create the final formatted output\n",
    "formatted_inference_data = formatted_df.apply(lambda row: format_for_inference(row), axis=1)\n",
    "\n",
    "# Convert the result into a list of formatted inference data\n",
    "formatted_inference_list = formatted_inference_data.tolist()\n",
    "\n",
    "# Create a DataFrame from the formatted inference data\n",
    "formatted_inference_df = pd.DataFrame(formatted_inference_list)\n",
    "\n",
    "# Save or print the first few rows of the formatted inference data\n",
    "# formatted_inference_df.to_csv('formatted_inference_data.csv', index=False)\n",
    "print(formatted_inference_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ea9bd-7116-4278-8b8c-c0ef02d8020b",
   "metadata": {},
   "source": [
    "# Splitting into Train, Validation & Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "execution_state": "idle",
   "id": "64904b42-13eb-4df8-8e05-e16018b68c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(formatted_inference_df, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "val_data.to_csv('val_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "execution_state": "idle",
   "id": "af2726c1-0721-4ffc-b393-b505dde9b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.columns = train_data.columns.str.strip()\n",
    "# gdf_master_data.columns = gdf_master_data.columns.str.strip()\n",
    "\n",
    "# def create_instructions(data_row, gdf_data):\n",
    "#     raw_field = data_row['raw_field']\n",
    "#     raw_desc = data_row['raw_desc']\n",
    "#     gdf_field = data_row['gdf_field']\n",
    "\n",
    "#     gdf_field = str(gdf_field).strip()\n",
    "\n",
    "#     gdf_desc = gdf_data[gdf_data['gdf_field'].str.strip() == gdf_field]['gdf_desc'].values\n",
    "\n",
    "#     if len(gdf_desc) == 0:\n",
    "#         gdf_desc = \"Description not found.\"\n",
    "\n",
    "#     # Instruction: \"Map the raw field (example 'dt') to a standardized GDF field\"\n",
    "#     instruction = f\"Map the raw field '{raw_field}' to a standardized GDF field.\"\n",
    "\n",
    "#     # Context: Include raw description and GDF description for context\n",
    "#     context = f\"Raw field description: {raw_desc}\\nGDF field: {gdf_field}\\nGDF field description: {gdf_desc[0]}\"\n",
    "\n",
    "#     response = f\"The raw field '{raw_field}' should be mapped to the GDF field '{gdf_field}'.\"\n",
    "\n",
    "#     return {\n",
    "#         'instruction': instruction,\n",
    "#         'context': context,\n",
    "#         'response': response\n",
    "#     }\n",
    "\n",
    "# formatted_data = train_data.apply(lambda row: create_instructions(train_data, gdf_master_data), axis=1)\n",
    "\n",
    "# formatted_data_list = formatted_data.tolist()\n",
    "\n",
    "# formatted_df = pd.DataFrame(formatted_data_list)\n",
    "# print(formatted_df.head())\n",
    "\n",
    "# train_data, test_data = train_test_split(formatted_df, test_size=0.2, random_state=42)\n",
    "# train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# train_data.to_csv('train_data.csv', index=False)\n",
    "# val_data.to_csv('val_data.csv', index=False)\n",
    "# test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "execution_state": "idle",
   "id": "486f52cf-db7f-4c0b-9bdd-131f355fe086",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(load_in_8bit=True, llm_int8_threshold=6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bd7303-58bc-4cdd-a5b2-c18f513c02e9",
   "metadata": {},
   "source": [
    "# Tokenizing the Datasets for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "execution_state": "idle",
   "id": "38731032-845f-45c7-ac3c-c6d117dbe547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/26/25 20:28:25] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> Using custom data configuration default-1fbd708ae141654d                <a href=\"file:///opt/conda/lib/python3.11/site-packages/datasets/builder.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">builder.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/datasets/builder.py#392\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">392</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/26/25 20:28:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m Using custom data configuration default-1fbd708ae141654d                \u001b]8;id=545410;file:///opt/conda/lib/python3.11/site-packages/datasets/builder.py\u001b\\\u001b[2mbuilder.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=82403;file:///opt/conda/lib/python3.11/site-packages/datasets/builder.py#392\u001b\\\u001b[2m392\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sagemaker-user/.cache/huggingface/datasets/csv/default-1fbd708ae141654d/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bd80ef66ae484b9fa79dd2769b5c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ca4de26cf34132a74e2b74c14d3163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 1 train_dataset = <span style=\"font-weight: bold; text-decoration: underline\">load_dataset(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">'csv'</span><span style=\"font-weight: bold; text-decoration: underline\">, data_files=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">'train_data.csv'</span><span style=\"font-weight: bold; text-decoration: underline\">, split=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">'train'</span><span style=\"font-weight: bold; text-decoration: underline\">)</span>             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>val_dataset = load_dataset(<span style=\"color: #808000; text-decoration-color: #808000\">'csv'</span>, data_files=<span style=\"color: #808000; text-decoration-color: #808000\">'val_data.csv'</span>, split=<span style=\"color: #808000; text-decoration-color: #808000\">'train'</span>)                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>test_dataset = load_dataset(<span style=\"color: #808000; text-decoration-color: #808000\">'csv'</span>, data_files=<span style=\"color: #808000; text-decoration-color: #808000\">'test_data.csv'</span>, split=<span style=\"color: #808000; text-decoration-color: #808000\">'train'</span>)               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">load.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1731</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_dataset</span>                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1728 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>try_from_hf_gcs = path <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> _PACKAGED_DATASETS_MODULES                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1729 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1730 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Download and prepare data</span>                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1731 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>builder_instance.download_and_prepare(                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1732 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>download_config=download_config,                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1733 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>download_mode=download_mode,                                                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1734 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>ignore_verifications=ignore_verifications,                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">builder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">613</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">download_and_prepare</span>          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 610 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ConnectionError</span>:                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 611 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>logger.warning(<span style=\"color: #808000; text-decoration-color: #808000\">\"HF google storage unreachable. Downloading a</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 612 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> downloaded_from_gcs:                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 613 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">._download_and_prepare(</span>                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 614 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\">│   │   │   │   │   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">dl_manager=dl_manager, verify_infos=verify_infos, **download</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 615 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\">│   │   │   │   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 616 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Sync info</span>                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">builder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">702</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_download_and_prepare</span>         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 699 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 700 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 701 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Prepare split will record examples associated to the split</span>              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 702 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._prepare_split(split_generator, **prepare_split_kwargs)              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 703 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">OSError</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 704 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">OSError</span>(                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 705 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Cannot find data file. \"</span>                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">builder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1164</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_prepare_split</span>               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1161 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>generator = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._generate_tables(**split_generator.gen_kwargs)                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ArrowWriter(features=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.info.features, path=fpath) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> writer:              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1164 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">for</span><span style=\"font-weight: bold; text-decoration: underline\"> key, table </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold; text-decoration: underline\">in</span><span style=\"font-weight: bold; text-decoration: underline\"> logging.tqdm(</span>                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1165 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\">│   │   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">generator, unit=</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">\" tables\"</span><span style=\"font-weight: bold; text-decoration: underline\">, leave=</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">False</span><span style=\"font-weight: bold; text-decoration: underline\">, disable=</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">True</span><span style=\"font-weight: bold; text-decoration: underline\">  </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\"># not logging.is_p</span>  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\">│   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">):</span>                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\">│   │   │   │   </span><span style=\"font-weight: bold; text-decoration: underline\">writer.write_table(table)</span>                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/tqdm/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">notebook.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">250</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">247 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">248 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">249 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>it = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>()                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>250 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> obj <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> it:                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">251 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># return super(tqdm...) will not catch exception</span>                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">252 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> obj                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">253 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># NB: except ... [ as ...] breaks IPython async KeyboardInterrupt</span>                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/tqdm/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">std.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1169</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If the bar is disabled, then just walk the iterable</span>                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># (note: keep this check outside the loop for performance)</span>                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.disable:                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1169 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">for</span><span style=\"font-weight: bold; text-decoration: underline\"> obj </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold; text-decoration: underline\">in</span><span style=\"font-weight: bold; text-decoration: underline\"> iterable:</span>                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1170 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold; text-decoration: underline\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">yield</span><span style=\"font-weight: bold; text-decoration: underline\"> obj</span>                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1171 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1172 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.11/site-packages/datasets/packaged_modules/csv/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">csv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">154</span> in              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_generate_tables</span>                                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">151 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># dtype allows reading an int column as str</span>                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">152 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>dtype = {name: dtype.to_pandas_dtype() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> name, dtype <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">zip</span>(schema.names, sche   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">153 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> file_idx, file <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(files):                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>154 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>csv_file_reader = <span style=\"font-weight: bold; text-decoration: underline\">pd.read_csv(file, iterator=</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">True</span><span style=\"font-weight: bold; text-decoration: underline\">, dtype=dtype, **</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">.confi</span>   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">155 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> batch_idx, df <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(csv_file_reader):                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>pa_table = pa.Table.from_pandas(df, schema=schema)                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #e100e1; text-decoration-color: #e100e1; font-weight: bold\">read_csv</span><span style=\"font-weight: bold\">()</span> got an unexpected keyword argument <span style=\"color: #008700; text-decoration-color: #008700\">'mangle_dupe_cols'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m 1 train_dataset = \u001b[1;4mload_dataset(\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mcsv\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4m, data_files=\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mtrain_data.csv\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4m, split=\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mtrain\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4m)\u001b[0m             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 2 \u001b[0mval_dataset = load_dataset(\u001b[33m'\u001b[0m\u001b[33mcsv\u001b[0m\u001b[33m'\u001b[0m, data_files=\u001b[33m'\u001b[0m\u001b[33mval_data.csv\u001b[0m\u001b[33m'\u001b[0m, split=\u001b[33m'\u001b[0m\u001b[33mtrain\u001b[0m\u001b[33m'\u001b[0m)                 \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 3 \u001b[0mtest_dataset = load_dataset(\u001b[33m'\u001b[0m\u001b[33mcsv\u001b[0m\u001b[33m'\u001b[0m, data_files=\u001b[33m'\u001b[0m\u001b[33mtest_data.csv\u001b[0m\u001b[33m'\u001b[0m, split=\u001b[33m'\u001b[0m\u001b[33mtrain\u001b[0m\u001b[33m'\u001b[0m)               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 4 \u001b[0m                                                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/datasets/\u001b[0m\u001b[1;33mload.py\u001b[0m:\u001b[94m1731\u001b[0m in \u001b[92mload_dataset\u001b[0m                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1728 \u001b[0m\u001b[2m│   \u001b[0mtry_from_hf_gcs = path \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m _PACKAGED_DATASETS_MODULES                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1729 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1730 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Download and prepare data\u001b[0m                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m1731 \u001b[2m│   \u001b[0mbuilder_instance.download_and_prepare(                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1732 \u001b[0m\u001b[2m│   │   \u001b[0mdownload_config=download_config,                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1733 \u001b[0m\u001b[2m│   │   \u001b[0mdownload_mode=download_mode,                                                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1734 \u001b[0m\u001b[2m│   │   \u001b[0mignore_verifications=ignore_verifications,                                        \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/datasets/\u001b[0m\u001b[1;33mbuilder.py\u001b[0m:\u001b[94m613\u001b[0m in \u001b[92mdownload_and_prepare\u001b[0m          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 610 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mConnectionError\u001b[0m:                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 611 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mlogger.warning(\u001b[33m\"\u001b[0m\u001b[33mHF google storage unreachable. Downloading a\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 612 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m downloaded_from_gcs:                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m 613 \u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m._download_and_prepare(\u001b[0m                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 614 \u001b[0m\u001b[1;2;4m│   │   │   │   │   │   │   \u001b[0m\u001b[1;4mdl_manager=dl_manager, verify_infos=verify_infos, **download\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 615 \u001b[0m\u001b[1;2;4m│   │   │   │   │   │   \u001b[0m\u001b[1;4m)\u001b[0m                                                                 \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 616 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# Sync info\u001b[0m                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/datasets/\u001b[0m\u001b[1;33mbuilder.py\u001b[0m:\u001b[94m702\u001b[0m in \u001b[92m_download_and_prepare\u001b[0m         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 699 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 700 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 701 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Prepare split will record examples associated to the split\u001b[0m              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m 702 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._prepare_split(split_generator, **prepare_split_kwargs)              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 703 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mOSError\u001b[0m \u001b[94mas\u001b[0m e:                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 704 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mOSError\u001b[0m(                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 705 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCannot find data file. \u001b[0m\u001b[33m\"\u001b[0m                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/datasets/\u001b[0m\u001b[1;33mbuilder.py\u001b[0m:\u001b[94m1164\u001b[0m in \u001b[92m_prepare_split\u001b[0m               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1161 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1162 \u001b[0m\u001b[2m│   │   \u001b[0mgenerator = \u001b[96mself\u001b[0m._generate_tables(**split_generator.gen_kwargs)                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1163 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ArrowWriter(features=\u001b[96mself\u001b[0m.info.features, path=fpath) \u001b[94mas\u001b[0m writer:              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m1164 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mfor\u001b[0m\u001b[1;4m key, table \u001b[0m\u001b[1;4;95min\u001b[0m\u001b[1;4m logging.tqdm(\u001b[0m                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1165 \u001b[0m\u001b[1;2;4m│   │   │   │   \u001b[0m\u001b[1;4mgenerator, unit=\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33m tables\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m, leave=\u001b[0m\u001b[1;4;94mFalse\u001b[0m\u001b[1;4m, disable=\u001b[0m\u001b[1;4;94mTrue\u001b[0m\u001b[1;4m  \u001b[0m\u001b[1;2;4m# not logging.is_p\u001b[0m  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1166 \u001b[0m\u001b[1;2;4m│   │   │   \u001b[0m\u001b[1;4m):\u001b[0m                                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1167 \u001b[0m\u001b[1;2;4m│   │   │   │   \u001b[0m\u001b[1;4mwriter.write_table(table)\u001b[0m                                                 \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/tqdm/\u001b[0m\u001b[1;33mnotebook.py\u001b[0m:\u001b[94m250\u001b[0m in \u001b[92m__iter__\u001b[0m                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m__iter__\u001b[0m(\u001b[96mself\u001b[0m):                                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   │   \u001b[0mit = \u001b[96msuper\u001b[0m().\u001b[92m__iter__\u001b[0m()                                                        \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m250 \u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m obj \u001b[95min\u001b[0m it:                                                                 \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m251 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# return super(tqdm...) will not catch exception\u001b[0m                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94myield\u001b[0m obj                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[0m                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/tqdm/\u001b[0m\u001b[1;33mstd.py\u001b[0m:\u001b[94m1169\u001b[0m in \u001b[92m__iter__\u001b[0m                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# If the bar is disabled, then just walk the iterable\u001b[0m                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1167 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# (note: keep this check outside the loop for performance)\u001b[0m                        \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1168 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.disable:                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m1169 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mfor\u001b[0m\u001b[1;4m obj \u001b[0m\u001b[1;4;95min\u001b[0m\u001b[1;4m iterable:\u001b[0m                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1170 \u001b[0m\u001b[1;2;4m│   │   │   │   \u001b[0m\u001b[1;4;94myield\u001b[0m\u001b[1;4m obj\u001b[0m                                                                 \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1171 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                        \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1172 \u001b[0m                                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.11/site-packages/datasets/packaged_modules/csv/\u001b[0m\u001b[1;33mcsv.py\u001b[0m:\u001b[94m154\u001b[0m in              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[92m_generate_tables\u001b[0m                                                                                 \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m151 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# dtype allows reading an int column as str\u001b[0m                                        \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   \u001b[0mdtype = {name: dtype.to_pandas_dtype() \u001b[94mfor\u001b[0m name, dtype \u001b[95min\u001b[0m \u001b[96mzip\u001b[0m(schema.names, sche   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m file_idx, file \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(files):                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m154 \u001b[2m│   │   │   \u001b[0mcsv_file_reader = \u001b[1;4mpd.read_csv(file, iterator=\u001b[0m\u001b[1;4;94mTrue\u001b[0m\u001b[1;4m, dtype=dtype, **\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.confi\u001b[0m   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m batch_idx, df \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(csv_file_reader):                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpa_table = pa.Table.from_pandas(df, schema=schema)                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;38;2;225;0;225mread_csv\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m got an unexpected keyword argument \u001b[38;2;0;135;0m'mangle_dupe_cols'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = load_dataset('csv', data_files='train_data.csv', split='train')\n",
    "val_dataset = load_dataset('csv', data_files='val_data.csv', split='train')\n",
    "test_dataset = load_dataset('csv', data_files='test_data.csv', split='train')\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-3B-Instruct')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the datasets\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples['instruction'], examples['context'], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    inputs['labels'] = inputs['input_ids'].copy()\n",
    "    return inputs\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# # Set format for PyTorch (or TensorFlow)\n",
    "# train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'response'])\n",
    "# val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'response'])\n",
    "# test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'response'])\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d70f8b9-8f13-4639-888f-5f4720b8d0ca",
   "metadata": {},
   "source": [
    "# Training Llama 3.2 3B Instruct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9309f59c-e594-432b-b34e-49052d3859ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fe385a25f047ae872ebc0700d00e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3019/310232787.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2541' max='2541' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2541/2541 40:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.030816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.021036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.020876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2541, training_loss=0.14858478229802244, metrics={'train_runtime': 2449.6873, 'train_samples_per_second': 2.073, 'train_steps_per_second': 1.037, 'total_flos': 4.401582492981658e+16, 'train_loss': 0.14858478229802244, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Llama model for causal language modeling\n",
    "model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', quantization_config=bnb_config)\n",
    "\n",
    "# Define LoRA Configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # LoRA rank\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",  \n",
    "    task_type=\"CAUSAL_LM\", \n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(model, lora_config)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\", \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d64bb034-c613-4cdc-abc7-c012bfcfb590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='363' max='236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [236/236 19:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 0.020876113325357437, 'eval_runtime': 89.4046, 'eval_samples_per_second': 5.268, 'eval_steps_per_second': 2.64, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2800925f-2832-4f3c-88ff-478fef5d1397",
   "metadata": {},
   "source": [
    "# Saving the Model Locally & in S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4efd3fe2-d537-476e-acd9-922294286055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model/tokenizer_config.json',\n",
       " './fine_tuned_model/special_tokens_map.json',\n",
       " './fine_tuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = './fine_tuned_model' \n",
    "\n",
    "model.save_pretrained(model_save_path)\n",
    "\n",
    "tokenizer.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62a5d151-0839-4b18-8909-63f0ab32d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./fine_tuned_model/config.json to s3://sagemaker-bucket-fine-tuning/llama_3.2_3B_Instruct_finetuned/config.json\n",
      "Uploading ./fine_tuned_model/generation_config.json to s3://sagemaker-bucket-fine-tuning/llama_3.2_3B_Instruct_finetuned/generation_config.json\n",
      "Uploading ./fine_tuned_model/model.safetensors to s3://sagemaker-bucket-fine-tuning/llama_3.2_3B_Instruct_finetuned/model.safetensors\n",
      "Uploading ./fine_tuned_model/tokenizer_config.json to s3://sagemaker-bucket-fine-tuning/llama_3.2_3B_Instruct_finetuned/tokenizer_config.json\n",
      "Uploading ./fine_tuned_model/special_tokens_map.json to s3://sagemaker-bucket-fine-tuning/llama_3.2_3B_Instruct_finetuned/special_tokens_map.json\n",
      "Uploading ./fine_tuned_model/tokenizer.json to s3://sagemaker-bucket-fine-tuning/llama_3.2_3B_Instruct_finetuned/tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'sagemaker-bucket-fine-tuning'\n",
    "s3_folder = 'llama_3.2_3B_Instruct_finetuned' \n",
    "\n",
    "local_model_dir = './fine_tuned_model'\n",
    "\n",
    "for root, dirs, files in os.walk(local_model_dir):\n",
    "    for file in files:\n",
    "        local_file_path = os.path.join(root, file)\n",
    "        s3_key = os.path.join(s3_folder, Path(local_file_path).relative_to(local_model_dir))\n",
    "\n",
    "        print(f\"Uploading {local_file_path} to s3://{bucket_name}/{s3_key}\")\n",
    "        s3_client.upload_file(local_file_path, bucket_name, s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c6635-f708-4d9c-b5ed-d7f1fabceeee",
   "metadata": {},
   "source": [
    "# Loading the Model from S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b532663b-b3a2-4cbc-b7fb-ffeab2e79bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading llama_3.2_3B_Instruct_finetuned/generation_config.json from S3 to ./test/generation_config.json\n",
      "Downloading llama_3.2_3B_Instruct_finetuned/config.json from S3 to ./test/config.json\n",
      "Downloading llama_3.2_3B_Instruct_finetuned/tokenizer.json from S3 to ./test/tokenizer.json\n",
      "Downloading llama_3.2_3B_Instruct_finetuned/tokenizer_config.json from S3 to ./test/tokenizer_config.json\n",
      "Downloading llama_3.2_3B_Instruct_finetuned/special_tokens_map.json from S3 to ./test/special_tokens_map.json\n",
      "Downloading llama_3.2_3B_Instruct_finetuned/model.safetensors from S3 to ./test/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'sagemaker-bucket-fine-tuning'\n",
    "s3_folder = 'llama_3.2_3B_Instruct_finetuned'  \n",
    "\n",
    "local_model_dir = './test'\n",
    "\n",
    "os.makedirs(local_model_dir, exist_ok=True)\n",
    "\n",
    "files = [\n",
    "    'generation_config.json',   \n",
    "    'config.json',       \n",
    "    'tokenizer.json',          \n",
    "    'tokenizer_config.json', \n",
    "    'special_tokens_map.json',\n",
    "    'model.safetensors',\n",
    "]\n",
    "\n",
    "# Download the files from S3 to the local directory\n",
    "for file in files:\n",
    "    local_file_path = os.path.join(local_model_dir, file)\n",
    "    s3_key = os.path.join(s3_folder, file)\n",
    "\n",
    "    print(f\"Downloading {s3_key} from S3 to {local_file_path}\")\n",
    "    s3_client.download_file(bucket_name, s3_key, local_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7657ef40-abd3-45e2-baa1-42c5fb9fa5e9",
   "metadata": {},
   "source": [
    "# Making predictions on Test Data for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac5a1613-ba30-4b3f-b864-bbf25e4f0b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [   791    279   7257   2115    364     15   1733   2759    609    198\n",
      "     16    286  12751    355    479  39329   4229    198     17    996\n",
      "  28174  39329   4229    198     18    996  28174  39329   4229    198\n",
      "     19    996  28174  39329   4229    198    338   2564  16554  11727\n",
      "     23   1881   2605  13275   1292    198  11727     24    996   2605\n",
      "  28224    535   4257    198  12422     15    338   4751   4257    198\n",
      "  12422     16    415   2605   4257   2769  29579    198  12422     17\n",
      "    415  13072  30618  21640    198    678     25   7257   5121     11\n",
      "  17736     25    220  12422     18     11  13534     25   1665      6\n",
      "    311    264  51114    480   5375   2115     13 128000  20613   2115\n",
      "   4096     25    220     15   6794  33278    198     16   6794  33278\n",
      "    198     17    996   2944   2082    369    279  28174    198     18\n",
      "    996   2944   2082    369    279  28174    198     19    996   2944\n",
      "   2082    369    279  28174    198   3909   2564  27381  11727     23\n",
      "   7714  33278    198  11727     24   7714  33278    198  12422     15\n",
      "   7714  33278    198  12422     16   7714  33278    198  12422     17\n",
      "   7714  33278    198    678     25   7257  11229     11  17736     25\n",
      "    220  12422     18     11  13534     25   1665    198     38   5375\n",
      "   2115     25    220     15   1408   6969  20734   4813    198     16\n",
      "    338   6969  23326  49102   5441  73045  10225     62   2437    198\n",
      "     17    338   6969  23326  49102   5441  73045  10225     62   1721\n",
      "    198     18    338   6969  23326  49102   5441  73045  10225     62\n",
      "   2839    198     19    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2371    198   5218   2564  37677  11727     23    262  15643\n",
      "  63642  20739  55736  37372   4813    198  11727     24    310  15643\n",
      "  63642  20739  13343  19007    198  12422     15    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     16    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     17   1835  15643  63642\n",
      "  49219  42103   1341  12121    198    678     25    342   3013   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "    198     38   5375   2115   4096     25    423 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009], True Label: [128000   2276    279   7257   2115    364     15   1733   2759    609\n",
      "    198     16    286  12751    355    479  39329   4229    198     17\n",
      "    996  28174  39329   4229    198     18    996  28174  39329   4229\n",
      "    198     19    996  28174  39329   4229    198    338   2564  16554\n",
      "  11727     23   1881   2605  13275   1292    198  11727     24    996\n",
      "   2605  28224    535   4257    198  12422     15    338   4751   4257\n",
      "    198  12422     16    415   2605   4257   2769  29579    198  12422\n",
      "     17    415  13072  30618  21640    198    678     25   7257   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "      6    311    264  51114    480   5375   2115     13 128000  20613\n",
      "   2115   4096     25    220     15   6794  33278    198     16   6794\n",
      "  33278    198     17    996   2944   2082    369    279  28174    198\n",
      "     18    996   2944   2082    369    279  28174    198     19    996\n",
      "   2944   2082    369    279  28174    198   3909   2564  27381  11727\n",
      "     23   7714  33278    198  11727     24   7714  33278    198  12422\n",
      "     15   7714  33278    198  12422     16   7714  33278    198  12422\n",
      "     17   7714  33278    198    678     25   7257  11229     11  17736\n",
      "     25    220  12422     18     11  13534     25   1665    198     38\n",
      "   5375   2115     25    220     15   1408   6969  20734   4813    198\n",
      "     16    338   6969  23326  49102   5441  73045  10225     62   2437\n",
      "    198     17    338   6969  23326  49102   5441  73045  10225     62\n",
      "   1721    198     18    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2839    198     19    338   6969  23326  49102   5441  73045\n",
      "  10225     62   2371    198   5218   2564  37677  11727     23    262\n",
      "  15643  63642  20739  55736  37372   4813    198  11727     24    310\n",
      "  15643  63642  20739  13343  19007    198  12422     15    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     16    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     17   1835  15643\n",
      "  63642  49219  42103   1341  12121    198    678     25    342   3013\n",
      "   5121     11  17736     25    220  12422     18     11  13534     25\n",
      "   1665    198     38   5375   2115   4096     25    423 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009]\n",
      "Prediction: [   791    279   7257   2115    364     15   1733   2759    609    198\n",
      "     16    286  12751    355    479  39329   4229    198     17    996\n",
      "  28174  39329   4229    198     18    996  28174  39329   4229    198\n",
      "     19    996  28174  39329   4229    198    338   2564  16554  11727\n",
      "     23   1881   2605  13275   1292    198  11727     24    996   2605\n",
      "  28224    535   4257    198  12422     15    338   4751   4257    198\n",
      "  12422     16    415   2605   4257   2769  29579    198  12422     17\n",
      "    415  13072  30618  21640    198    678     25   7257   5121     11\n",
      "  17736     25    220  12422     18     11  13534     25   1665      6\n",
      "    311    264  51114    480   5375   2115     13 128000  20613   2115\n",
      "   4096     25    220     15   6794  33278    198     16   6794  33278\n",
      "    198     17    996   2944   2082    369    279  28174    198     18\n",
      "    996   2944   2082    369    279  28174    198     19    996   2944\n",
      "   2082    369    279  28174    198   3909   2564  27381  11727     23\n",
      "   7714  33278    198  11727     24   7714  33278    198  12422     15\n",
      "   7714  33278    198  12422     16   7714  33278    198  12422     17\n",
      "   7714  33278    198    678     25   7257  11229     11  17736     25\n",
      "    220  12422     18     11  13534     25   1665    198     38   5375\n",
      "   2115     25    220     15   1408   6969  20734   4813    198     16\n",
      "    338   6969  23326  49102   5441  73045  10225     62   2437    198\n",
      "     17    338   6969  23326  49102   5441  73045  10225     62   1721\n",
      "    198     18    338   6969  23326  49102   5441  73045  10225     62\n",
      "   2839    198     19    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2371    198   5218   2564  37677  11727     23    262  15643\n",
      "  63642  20739  55736  37372   4813    198  11727     24    310  15643\n",
      "  63642  20739  13343  19007    198  12422     15    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     16    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     17   1835  15643  63642\n",
      "  49219  42103   1341  12121    198    678     25    342   3013   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "    198     38   5375   2115   4096     25    423 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009], True Label: [128000   2276    279   7257   2115    364     15   1733   2759    609\n",
      "    198     16    286  12751    355    479  39329   4229    198     17\n",
      "    996  28174  39329   4229    198     18    996  28174  39329   4229\n",
      "    198     19    996  28174  39329   4229    198    338   2564  16554\n",
      "  11727     23   1881   2605  13275   1292    198  11727     24    996\n",
      "   2605  28224    535   4257    198  12422     15    338   4751   4257\n",
      "    198  12422     16    415   2605   4257   2769  29579    198  12422\n",
      "     17    415  13072  30618  21640    198    678     25   7257   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "      6    311    264  51114    480   5375   2115     13 128000  20613\n",
      "   2115   4096     25    220     15   6794  33278    198     16   6794\n",
      "  33278    198     17    996   2944   2082    369    279  28174    198\n",
      "     18    996   2944   2082    369    279  28174    198     19    996\n",
      "   2944   2082    369    279  28174    198   3909   2564  27381  11727\n",
      "     23   7714  33278    198  11727     24   7714  33278    198  12422\n",
      "     15   7714  33278    198  12422     16   7714  33278    198  12422\n",
      "     17   7714  33278    198    678     25   7257  11229     11  17736\n",
      "     25    220  12422     18     11  13534     25   1665    198     38\n",
      "   5375   2115     25    220     15   1408   6969  20734   4813    198\n",
      "     16    338   6969  23326  49102   5441  73045  10225     62   2437\n",
      "    198     17    338   6969  23326  49102   5441  73045  10225     62\n",
      "   1721    198     18    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2839    198     19    338   6969  23326  49102   5441  73045\n",
      "  10225     62   2371    198   5218   2564  37677  11727     23    262\n",
      "  15643  63642  20739  55736  37372   4813    198  11727     24    310\n",
      "  15643  63642  20739  13343  19007    198  12422     15    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     16    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     17   1835  15643\n",
      "  63642  49219  42103   1341  12121    198    678     25    342   3013\n",
      "   5121     11  17736     25    220  12422     18     11  13534     25\n",
      "   1665    198     38   5375   2115   4096     25    423 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009]\n",
      "Prediction: [   791    279   7257   2115    364     15   1733   2759    609    198\n",
      "     16    286  12751    355    479  39329   4229    198     17    996\n",
      "  28174  39329   4229    198     18    996  28174  39329   4229    198\n",
      "     19    996  28174  39329   4229    198    338   2564  16554  11727\n",
      "     23   1881   2605  13275   1292    198  11727     24    996   2605\n",
      "  28224    535   4257    198  12422     15    338   4751   4257    198\n",
      "  12422     16    415   2605   4257   2769  29579    198  12422     17\n",
      "    415  13072  30618  21640    198    678     25   7257   5121     11\n",
      "  17736     25    220  12422     18     11  13534     25   1665      6\n",
      "    311    264  51114    480   5375   2115     13 128000  20613   2115\n",
      "   4096     25    220     15   6794  33278    198     16   6794  33278\n",
      "    198     17    996   2944   2082    369    279  28174    198     18\n",
      "    996   2944   2082    369    279  28174    198     19    996   2944\n",
      "   2082    369    279  28174    198   3909   2564  27381  11727     23\n",
      "   7714  33278    198  11727     24   7714  33278    198  12422     15\n",
      "   7714  33278    198  12422     16   7714  33278    198  12422     17\n",
      "   7714  33278    198    678     25   7257  11229     11  17736     25\n",
      "    220  12422     18     11  13534     25   1665    198     38   5375\n",
      "   2115     25    220     15   1408   6969  20734   4813    198     16\n",
      "    338   6969  23326  49102   5441  73045  10225     62   2437    198\n",
      "     17    338   6969  23326  49102   5441  73045  10225     62   1721\n",
      "    198     18    338   6969  23326  49102   5441  73045  10225     62\n",
      "   2839    198     19    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2371    198   5218   2564  37677  11727     23    262  15643\n",
      "  63642  20739  55736  37372   4813    198  11727     24    310  15643\n",
      "  63642  20739  13343  19007    198  12422     15    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     16    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     17   1835  15643  63642\n",
      "  49219  42103   1341  12121    198    678     25    342   3013   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "    198     38   5375   2115   4096     25    423 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009], True Label: [128000   2276    279   7257   2115    364     15   1733   2759    609\n",
      "    198     16    286  12751    355    479  39329   4229    198     17\n",
      "    996  28174  39329   4229    198     18    996  28174  39329   4229\n",
      "    198     19    996  28174  39329   4229    198    338   2564  16554\n",
      "  11727     23   1881   2605  13275   1292    198  11727     24    996\n",
      "   2605  28224    535   4257    198  12422     15    338   4751   4257\n",
      "    198  12422     16    415   2605   4257   2769  29579    198  12422\n",
      "     17    415  13072  30618  21640    198    678     25   7257   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "      6    311    264  51114    480   5375   2115     13 128000  20613\n",
      "   2115   4096     25    220     15   6794  33278    198     16   6794\n",
      "  33278    198     17    996   2944   2082    369    279  28174    198\n",
      "     18    996   2944   2082    369    279  28174    198     19    996\n",
      "   2944   2082    369    279  28174    198   3909   2564  27381  11727\n",
      "     23   7714  33278    198  11727     24   7714  33278    198  12422\n",
      "     15   7714  33278    198  12422     16   7714  33278    198  12422\n",
      "     17   7714  33278    198    678     25   7257  11229     11  17736\n",
      "     25    220  12422     18     11  13534     25   1665    198     38\n",
      "   5375   2115     25    220     15   1408   6969  20734   4813    198\n",
      "     16    338   6969  23326  49102   5441  73045  10225     62   2437\n",
      "    198     17    338   6969  23326  49102   5441  73045  10225     62\n",
      "   1721    198     18    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2839    198     19    338   6969  23326  49102   5441  73045\n",
      "  10225     62   2371    198   5218   2564  37677  11727     23    262\n",
      "  15643  63642  20739  55736  37372   4813    198  11727     24    310\n",
      "  15643  63642  20739  13343  19007    198  12422     15    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     16    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     17   1835  15643\n",
      "  63642  49219  42103   1341  12121    198    678     25    342   3013\n",
      "   5121     11  17736     25    220  12422     18     11  13534     25\n",
      "   1665    198     38   5375   2115   4096     25    423 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009]\n",
      "Prediction: [   791    279   7257   2115    364     15   1733   2759    609    198\n",
      "     16    286  12751    355    479  39329   4229    198     17    996\n",
      "  28174  39329   4229    198     18    996  28174  39329   4229    198\n",
      "     19    996  28174  39329   4229    198    338   2564  16554  11727\n",
      "     23   1881   2605  13275   1292    198  11727     24    996   2605\n",
      "  28224    535   4257    198  12422     15    338   4751   4257    198\n",
      "  12422     16    415   2605   4257   2769  29579    198  12422     17\n",
      "    415  13072  30618  21640    198    678     25   7257   5121     11\n",
      "  17736     25    220  12422     18     11  13534     25   1665      6\n",
      "    311    264  51114    480   5375   2115     13 128000  20613   2115\n",
      "   4096     25    220     15   6794  33278    198     16   6794  33278\n",
      "    198     17    996   2944   2082    369    279  28174    198     18\n",
      "    996   2944   2082    369    279  28174    198     19    996   2944\n",
      "   2082    369    279  28174    198   3909   2564  27381  11727     23\n",
      "   7714  33278    198  11727     24   7714  33278    198  12422     15\n",
      "   7714  33278    198  12422     16   7714  33278    198  12422     17\n",
      "   7714  33278    198    678     25   7257  11229     11  17736     25\n",
      "    220  12422     18     11  13534     25   1665    198     38   5375\n",
      "   2115     25    220     15   1408   6969  20734   4813    198     16\n",
      "    338   6969  23326  49102   5441  73045  10225     62   2437    198\n",
      "     17    338   6969  23326  49102   5441  73045  10225     62   1721\n",
      "    198     18    338   6969  23326  49102   5441  73045  10225     62\n",
      "   2839    198     19    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2371    198   5218   2564  37677  11727     23    262  15643\n",
      "  63642  20739  55736  37372   4813    198  11727     24    310  15643\n",
      "  63642  20739  13343  19007    198  12422     15    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     16    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     17   1835  15643  63642\n",
      "  49219  42103   1341  12121    198    678     25    342   3013   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "    198     38   5375   2115   4096     25    423 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009], True Label: [128000   2276    279   7257   2115    364     15   1733   2759    609\n",
      "    198     16    286  12751    355    479  39329   4229    198     17\n",
      "    996  28174  39329   4229    198     18    996  28174  39329   4229\n",
      "    198     19    996  28174  39329   4229    198    338   2564  16554\n",
      "  11727     23   1881   2605  13275   1292    198  11727     24    996\n",
      "   2605  28224    535   4257    198  12422     15    338   4751   4257\n",
      "    198  12422     16    415   2605   4257   2769  29579    198  12422\n",
      "     17    415  13072  30618  21640    198    678     25   7257   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "      6    311    264  51114    480   5375   2115     13 128000  20613\n",
      "   2115   4096     25    220     15   6794  33278    198     16   6794\n",
      "  33278    198     17    996   2944   2082    369    279  28174    198\n",
      "     18    996   2944   2082    369    279  28174    198     19    996\n",
      "   2944   2082    369    279  28174    198   3909   2564  27381  11727\n",
      "     23   7714  33278    198  11727     24   7714  33278    198  12422\n",
      "     15   7714  33278    198  12422     16   7714  33278    198  12422\n",
      "     17   7714  33278    198    678     25   7257  11229     11  17736\n",
      "     25    220  12422     18     11  13534     25   1665    198     38\n",
      "   5375   2115     25    220     15   1408   6969  20734   4813    198\n",
      "     16    338   6969  23326  49102   5441  73045  10225     62   2437\n",
      "    198     17    338   6969  23326  49102   5441  73045  10225     62\n",
      "   1721    198     18    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2839    198     19    338   6969  23326  49102   5441  73045\n",
      "  10225     62   2371    198   5218   2564  37677  11727     23    262\n",
      "  15643  63642  20739  55736  37372   4813    198  11727     24    310\n",
      "  15643  63642  20739  13343  19007    198  12422     15    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     16    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     17   1835  15643\n",
      "  63642  49219  42103   1341  12121    198    678     25    342   3013\n",
      "   5121     11  17736     25    220  12422     18     11  13534     25\n",
      "   1665    198     38   5375   2115   4096     25    423 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009]\n",
      "Prediction: [   791    279   7257   2115    364     15   1733   2759    609    198\n",
      "     16    286  12751    355    479  39329   4229    198     17    996\n",
      "  28174  39329   4229    198     18    996  28174  39329   4229    198\n",
      "     19    996  28174  39329   4229    198    338   2564  16554  11727\n",
      "     23   1881   2605  13275   1292    198  11727     24    996   2605\n",
      "  28224    535   4257    198  12422     15    338   4751   4257    198\n",
      "  12422     16    415   2605   4257   2769  29579    198  12422     17\n",
      "    415  13072  30618  21640    198    678     25   7257   5121     11\n",
      "  17736     25    220  12422     18     11  13534     25   1665      6\n",
      "    311    264  51114    480   5375   2115     13 128000  20613   2115\n",
      "   4096     25    220     15   6794  33278    198     16   6794  33278\n",
      "    198     17    996   2944   2082    369    279  28174    198     18\n",
      "    996   2944   2082    369    279  28174    198     19    996   2944\n",
      "   2082    369    279  28174    198   3909   2564  27381  11727     23\n",
      "   7714  33278    198  11727     24   7714  33278    198  12422     15\n",
      "   7714  33278    198  12422     16   7714  33278    198  12422     17\n",
      "   7714  33278    198    678     25   7257  11229     11  17736     25\n",
      "    220  12422     18     11  13534     25   1665    198     38   5375\n",
      "   2115     25    220     15   1408   6969  20734   4813    198     16\n",
      "    338   6969  23326  49102   5441  73045  10225     62   2437    198\n",
      "     17    338   6969  23326  49102   5441  73045  10225     62   1721\n",
      "    198     18    338   6969  23326  49102   5441  73045  10225     62\n",
      "   2839    198     19    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2371    198   5218   2564  37677  11727     23    262  15643\n",
      "  63642  20739  55736  37372   4813    198  11727     24    310  15643\n",
      "  63642  20739  13343  19007    198  12422     15    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     16    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     17   1835  15643  63642\n",
      "  49219  42103   1341  12121    198    678     25    342   3013   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "    198     38   5375   2115   4096     25    423 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009], True Label: [128000   2276    279   7257   2115    364     15   1733   2759    609\n",
      "    198     16    286  12751    355    479  39329   4229    198     17\n",
      "    996  28174  39329   4229    198     18    996  28174  39329   4229\n",
      "    198     19    996  28174  39329   4229    198    338   2564  16554\n",
      "  11727     23   1881   2605  13275   1292    198  11727     24    996\n",
      "   2605  28224    535   4257    198  12422     15    338   4751   4257\n",
      "    198  12422     16    415   2605   4257   2769  29579    198  12422\n",
      "     17    415  13072  30618  21640    198    678     25   7257   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "      6    311    264  51114    480   5375   2115     13 128000  20613\n",
      "   2115   4096     25    220     15   6794  33278    198     16   6794\n",
      "  33278    198     17    996   2944   2082    369    279  28174    198\n",
      "     18    996   2944   2082    369    279  28174    198     19    996\n",
      "   2944   2082    369    279  28174    198   3909   2564  27381  11727\n",
      "     23   7714  33278    198  11727     24   7714  33278    198  12422\n",
      "     15   7714  33278    198  12422     16   7714  33278    198  12422\n",
      "     17   7714  33278    198    678     25   7257  11229     11  17736\n",
      "     25    220  12422     18     11  13534     25   1665    198     38\n",
      "   5375   2115     25    220     15   1408   6969  20734   4813    198\n",
      "     16    338   6969  23326  49102   5441  73045  10225     62   2437\n",
      "    198     17    338   6969  23326  49102   5441  73045  10225     62\n",
      "   1721    198     18    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2839    198     19    338   6969  23326  49102   5441  73045\n",
      "  10225     62   2371    198   5218   2564  37677  11727     23    262\n",
      "  15643  63642  20739  55736  37372   4813    198  11727     24    310\n",
      "  15643  63642  20739  13343  19007    198  12422     15    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     16    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     17   1835  15643\n",
      "  63642  49219  42103   1341  12121    198    678     25    342   3013\n",
      "   5121     11  17736     25    220  12422     18     11  13534     25\n",
      "   1665    198     38   5375   2115   4096     25    423 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009]\n",
      "Prediction: [   791    279   7257   2115    364     15   1733   2759    609    198\n",
      "     16    286  12751    355    479  39329   4229    198     17    996\n",
      "  28174  39329   4229    198     18    996  28174  39329   4229    198\n",
      "     19    996  28174  39329   4229    198    338   2564  16554  11727\n",
      "     23   1881   2605  13275   1292    198  11727     24    996   2605\n",
      "  28224    535   4257    198  12422     15    338   4751   4257    198\n",
      "  12422     16    415   2605   4257   2769  29579    198  12422     17\n",
      "    415  13072  30618  21640    198    678     25   7257   5121     11\n",
      "  17736     25    220  12422     18     11  13534     25   1665      6\n",
      "    311    264  51114    480   5375   2115     13 128000  20613   2115\n",
      "   4096     25    220     15   6794  33278    198     16   6794  33278\n",
      "    198     17    996   2944   2082    369    279  28174    198     18\n",
      "    996   2944   2082    369    279  28174    198     19    996   2944\n",
      "   2082    369    279  28174    198   3909   2564  27381  11727     23\n",
      "   7714  33278    198  11727     24   7714  33278    198  12422     15\n",
      "   7714  33278    198  12422     16   7714  33278    198  12422     17\n",
      "   7714  33278    198    678     25   7257  11229     11  17736     25\n",
      "    220  12422     18     11  13534     25   1665    198     38   5375\n",
      "   2115     25    220     15   1408   6969  20734   4813    198     16\n",
      "    338   6969  23326  49102   5441  73045  10225     62   2437    198\n",
      "     17    338   6969  23326  49102   5441  73045  10225     62   1721\n",
      "    198     18    338   6969  23326  49102   5441  73045  10225     62\n",
      "   2839    198     19    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2371    198   5218   2564  37677  11727     23    262  15643\n",
      "  63642  20739  55736  37372   4813    198  11727     24    310  15643\n",
      "  63642  20739  13343  19007    198  12422     15    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     16    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     17   1835  15643  63642\n",
      "  49219  42103   1341  12121    198    678     25    342   3013   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "    198     38   5375   2115   4096     25    423 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009], True Label: [128000   2276    279   7257   2115    364     15   1733   2759    609\n",
      "    198     16    286  12751    355    479  39329   4229    198     17\n",
      "    996  28174  39329   4229    198     18    996  28174  39329   4229\n",
      "    198     19    996  28174  39329   4229    198    338   2564  16554\n",
      "  11727     23   1881   2605  13275   1292    198  11727     24    996\n",
      "   2605  28224    535   4257    198  12422     15    338   4751   4257\n",
      "    198  12422     16    415   2605   4257   2769  29579    198  12422\n",
      "     17    415  13072  30618  21640    198    678     25   7257   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "      6    311    264  51114    480   5375   2115     13 128000  20613\n",
      "   2115   4096     25    220     15   6794  33278    198     16   6794\n",
      "  33278    198     17    996   2944   2082    369    279  28174    198\n",
      "     18    996   2944   2082    369    279  28174    198     19    996\n",
      "   2944   2082    369    279  28174    198   3909   2564  27381  11727\n",
      "     23   7714  33278    198  11727     24   7714  33278    198  12422\n",
      "     15   7714  33278    198  12422     16   7714  33278    198  12422\n",
      "     17   7714  33278    198    678     25   7257  11229     11  17736\n",
      "     25    220  12422     18     11  13534     25   1665    198     38\n",
      "   5375   2115     25    220     15   1408   6969  20734   4813    198\n",
      "     16    338   6969  23326  49102   5441  73045  10225     62   2437\n",
      "    198     17    338   6969  23326  49102   5441  73045  10225     62\n",
      "   1721    198     18    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2839    198     19    338   6969  23326  49102   5441  73045\n",
      "  10225     62   2371    198   5218   2564  37677  11727     23    262\n",
      "  15643  63642  20739  55736  37372   4813    198  11727     24    310\n",
      "  15643  63642  20739  13343  19007    198  12422     15    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     16    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     17   1835  15643\n",
      "  63642  49219  42103   1341  12121    198    678     25    342   3013\n",
      "   5121     11  17736     25    220  12422     18     11  13534     25\n",
      "   1665    198     38   5375   2115   4096     25    423 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009]\n",
      "Prediction: [   791    279   7257   2115    364     15   1733   2759    609    198\n",
      "     16    286  12751    355    479  39329   4229    198     17    996\n",
      "  28174  39329   4229    198     18    996  28174  39329   4229    198\n",
      "     19    996  28174  39329   4229    198    338   2564  16554  11727\n",
      "     23   1881   2605  13275   1292    198  11727     24    996   2605\n",
      "  28224    535   4257    198  12422     15    338   4751   4257    198\n",
      "  12422     16    415   2605   4257   2769  29579    198  12422     17\n",
      "    415  13072  30618  21640    198    678     25   7257   5121     11\n",
      "  17736     25    220  12422     18     11  13534     25   1665      6\n",
      "    311    264  51114    480   5375   2115     13 128000  20613   2115\n",
      "   4096     25    220     15   6794  33278    198     16   6794  33278\n",
      "    198     17    996   2944   2082    369    279  28174    198     18\n",
      "    996   2944   2082    369    279  28174    198     19    996   2944\n",
      "   2082    369    279  28174    198   3909   2564  27381  11727     23\n",
      "   7714  33278    198  11727     24   7714  33278    198  12422     15\n",
      "   7714  33278    198  12422     16   7714  33278    198  12422     17\n",
      "   7714  33278    198    678     25   7257  11229     11  17736     25\n",
      "    220  12422     18     11  13534     25   1665    198     38   5375\n",
      "   2115     25    220     15   1408   6969  20734   4813    198     16\n",
      "    338   6969  23326  49102   5441  73045  10225     62   2437    198\n",
      "     17    338   6969  23326  49102   5441  73045  10225     62   1721\n",
      "    198     18    338   6969  23326  49102   5441  73045  10225     62\n",
      "   2839    198     19    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2371    198   5218   2564  37677  11727     23    262  15643\n",
      "  63642  20739  55736  37372   4813    198  11727     24    310  15643\n",
      "  63642  20739  13343  19007    198  12422     15    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     16    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     17   1835  15643  63642\n",
      "  49219  42103   1341  12121    198    678     25    342   3013   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "    198     38   5375   2115   4096     25    423 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009], True Label: [128000   2276    279   7257   2115    364     15   1733   2759    609\n",
      "    198     16    286  12751    355    479  39329   4229    198     17\n",
      "    996  28174  39329   4229    198     18    996  28174  39329   4229\n",
      "    198     19    996  28174  39329   4229    198    338   2564  16554\n",
      "  11727     23   1881   2605  13275   1292    198  11727     24    996\n",
      "   2605  28224    535   4257    198  12422     15    338   4751   4257\n",
      "    198  12422     16    415   2605   4257   2769  29579    198  12422\n",
      "     17    415  13072  30618  21640    198    678     25   7257   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "      6    311    264  51114    480   5375   2115     13 128000  20613\n",
      "   2115   4096     25    220     15   6794  33278    198     16   6794\n",
      "  33278    198     17    996   2944   2082    369    279  28174    198\n",
      "     18    996   2944   2082    369    279  28174    198     19    996\n",
      "   2944   2082    369    279  28174    198   3909   2564  27381  11727\n",
      "     23   7714  33278    198  11727     24   7714  33278    198  12422\n",
      "     15   7714  33278    198  12422     16   7714  33278    198  12422\n",
      "     17   7714  33278    198    678     25   7257  11229     11  17736\n",
      "     25    220  12422     18     11  13534     25   1665    198     38\n",
      "   5375   2115     25    220     15   1408   6969  20734   4813    198\n",
      "     16    338   6969  23326  49102   5441  73045  10225     62   2437\n",
      "    198     17    338   6969  23326  49102   5441  73045  10225     62\n",
      "   1721    198     18    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2839    198     19    338   6969  23326  49102   5441  73045\n",
      "  10225     62   2371    198   5218   2564  37677  11727     23    262\n",
      "  15643  63642  20739  55736  37372   4813    198  11727     24    310\n",
      "  15643  63642  20739  13343  19007    198  12422     15    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     16    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     17   1835  15643\n",
      "  63642  49219  42103   1341  12121    198    678     25    342   3013\n",
      "   5121     11  17736     25    220  12422     18     11  13534     25\n",
      "   1665    198     38   5375   2115   4096     25    423 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009]\n",
      "Prediction: [   791    279   7257   2115    364     15   1733   2759    609    198\n",
      "     16    286  12751    355    479  39329   4229    198     17    996\n",
      "  28174  39329   4229    198     18    996  28174  39329   4229    198\n",
      "     19    996  28174  39329   4229    198    338   2564  16554  11727\n",
      "     23   1881   2605  13275   1292    198  11727     24    996   2605\n",
      "  28224    535   4257    198  12422     15    338   4751   4257    198\n",
      "  12422     16    415   2605   4257   2769  29579    198  12422     17\n",
      "    415  13072  30618  21640    198    678     25   7257   5121     11\n",
      "  17736     25    220  12422     18     11  13534     25   1665      6\n",
      "    311    264  51114    480   5375   2115     13 128000  20613   2115\n",
      "   4096     25    220     15   6794  33278    198     16   6794  33278\n",
      "    198     17    996   2944   2082    369    279  28174    198     18\n",
      "    996   2944   2082    369    279  28174    198     19    996   2944\n",
      "   2082    369    279  28174    198   3909   2564  27381  11727     23\n",
      "   7714  33278    198  11727     24   7714  33278    198  12422     15\n",
      "   7714  33278    198  12422     16   7714  33278    198  12422     17\n",
      "   7714  33278    198    678     25   7257  11229     11  17736     25\n",
      "    220  12422     18     11  13534     25   1665    198     38   5375\n",
      "   2115     25    220     15   1408   6969  20734   4813    198     16\n",
      "    338   6969  23326  49102   5441  73045  10225     62   2437    198\n",
      "     17    338   6969  23326  49102   5441  73045  10225     62   1721\n",
      "    198     18    338   6969  23326  49102   5441  73045  10225     62\n",
      "   2839    198     19    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2371    198   5218   2564  37677  11727     23    262  15643\n",
      "  63642  20739  55736  37372   4813    198  11727     24    310  15643\n",
      "  63642  20739  13343  19007    198  12422     15    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     16    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     17   1835  15643  63642\n",
      "  49219  42103   1341  12121    198    678     25    342   3013   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "    198     38   5375   2115   4096     25    423 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009], True Label: [128000   2276    279   7257   2115    364     15   1733   2759    609\n",
      "    198     16    286  12751    355    479  39329   4229    198     17\n",
      "    996  28174  39329   4229    198     18    996  28174  39329   4229\n",
      "    198     19    996  28174  39329   4229    198    338   2564  16554\n",
      "  11727     23   1881   2605  13275   1292    198  11727     24    996\n",
      "   2605  28224    535   4257    198  12422     15    338   4751   4257\n",
      "    198  12422     16    415   2605   4257   2769  29579    198  12422\n",
      "     17    415  13072  30618  21640    198    678     25   7257   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "      6    311    264  51114    480   5375   2115     13 128000  20613\n",
      "   2115   4096     25    220     15   6794  33278    198     16   6794\n",
      "  33278    198     17    996   2944   2082    369    279  28174    198\n",
      "     18    996   2944   2082    369    279  28174    198     19    996\n",
      "   2944   2082    369    279  28174    198   3909   2564  27381  11727\n",
      "     23   7714  33278    198  11727     24   7714  33278    198  12422\n",
      "     15   7714  33278    198  12422     16   7714  33278    198  12422\n",
      "     17   7714  33278    198    678     25   7257  11229     11  17736\n",
      "     25    220  12422     18     11  13534     25   1665    198     38\n",
      "   5375   2115     25    220     15   1408   6969  20734   4813    198\n",
      "     16    338   6969  23326  49102   5441  73045  10225     62   2437\n",
      "    198     17    338   6969  23326  49102   5441  73045  10225     62\n",
      "   1721    198     18    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2839    198     19    338   6969  23326  49102   5441  73045\n",
      "  10225     62   2371    198   5218   2564  37677  11727     23    262\n",
      "  15643  63642  20739  55736  37372   4813    198  11727     24    310\n",
      "  15643  63642  20739  13343  19007    198  12422     15    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     16    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     17   1835  15643\n",
      "  63642  49219  42103   1341  12121    198    678     25    342   3013\n",
      "   5121     11  17736     25    220  12422     18     11  13534     25\n",
      "   1665    198     38   5375   2115   4096     25    423 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009]\n",
      "Prediction: [   791    279   7257   2115    364     15   1733   2759    609    198\n",
      "     16    286  12751    355    479  39329   4229    198     17    996\n",
      "  28174  39329   4229    198     18    996  28174  39329   4229    198\n",
      "     19    996  28174  39329   4229    198    338   2564  16554  11727\n",
      "     23   1881   2605  13275   1292    198  11727     24    996   2605\n",
      "  28224    535   4257    198  12422     15    338   4751   4257    198\n",
      "  12422     16    415   2605   4257   2769  29579    198  12422     17\n",
      "    415  13072  30618  21640    198    678     25   7257   5121     11\n",
      "  17736     25    220  12422     18     11  13534     25   1665      6\n",
      "    311    264  51114    480   5375   2115     13 128000  20613   2115\n",
      "   4096     25    220     15   6794  33278    198     16   6794  33278\n",
      "    198     17    996   2944   2082    369    279  28174    198     18\n",
      "    996   2944   2082    369    279  28174    198     19    996   2944\n",
      "   2082    369    279  28174    198   3909   2564  27381  11727     23\n",
      "   7714  33278    198  11727     24   7714  33278    198  12422     15\n",
      "   7714  33278    198  12422     16   7714  33278    198  12422     17\n",
      "   7714  33278    198    678     25   7257  11229     11  17736     25\n",
      "    220  12422     18     11  13534     25   1665    198     38   5375\n",
      "   2115     25    220     15   1408   6969  20734   4813    198     16\n",
      "    338   6969  23326  49102   5441  73045  10225     62   2437    198\n",
      "     17    338   6969  23326  49102   5441  73045  10225     62   1721\n",
      "    198     18    338   6969  23326  49102   5441  73045  10225     62\n",
      "   2839    198     19    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2371    198   5218   2564  37677  11727     23    262  15643\n",
      "  63642  20739  55736  37372   4813    198  11727     24    310  15643\n",
      "  63642  20739  13343  19007    198  12422     15    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     16    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     17   1835  15643  63642\n",
      "  49219  42103   1341  12121    198    678     25    342   3013   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "    198     38   5375   2115   4096     25    423 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009], True Label: [128000   2276    279   7257   2115    364     15   1733   2759    609\n",
      "    198     16    286  12751    355    479  39329   4229    198     17\n",
      "    996  28174  39329   4229    198     18    996  28174  39329   4229\n",
      "    198     19    996  28174  39329   4229    198    338   2564  16554\n",
      "  11727     23   1881   2605  13275   1292    198  11727     24    996\n",
      "   2605  28224    535   4257    198  12422     15    338   4751   4257\n",
      "    198  12422     16    415   2605   4257   2769  29579    198  12422\n",
      "     17    415  13072  30618  21640    198    678     25   7257   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "      6    311    264  51114    480   5375   2115     13 128000  20613\n",
      "   2115   4096     25    220     15   6794  33278    198     16   6794\n",
      "  33278    198     17    996   2944   2082    369    279  28174    198\n",
      "     18    996   2944   2082    369    279  28174    198     19    996\n",
      "   2944   2082    369    279  28174    198   3909   2564  27381  11727\n",
      "     23   7714  33278    198  11727     24   7714  33278    198  12422\n",
      "     15   7714  33278    198  12422     16   7714  33278    198  12422\n",
      "     17   7714  33278    198    678     25   7257  11229     11  17736\n",
      "     25    220  12422     18     11  13534     25   1665    198     38\n",
      "   5375   2115     25    220     15   1408   6969  20734   4813    198\n",
      "     16    338   6969  23326  49102   5441  73045  10225     62   2437\n",
      "    198     17    338   6969  23326  49102   5441  73045  10225     62\n",
      "   1721    198     18    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2839    198     19    338   6969  23326  49102   5441  73045\n",
      "  10225     62   2371    198   5218   2564  37677  11727     23    262\n",
      "  15643  63642  20739  55736  37372   4813    198  11727     24    310\n",
      "  15643  63642  20739  13343  19007    198  12422     15    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     16    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     17   1835  15643\n",
      "  63642  49219  42103   1341  12121    198    678     25    342   3013\n",
      "   5121     11  17736     25    220  12422     18     11  13534     25\n",
      "   1665    198     38   5375   2115   4096     25    423 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009]\n",
      "Prediction: [   791    279   7257   2115    364     15   1733   2759    609    198\n",
      "     16    286  12751    355    479  39329   4229    198     17    996\n",
      "  28174  39329   4229    198     18    996  28174  39329   4229    198\n",
      "     19    996  28174  39329   4229    198    338   2564  16554  11727\n",
      "     23   1881   2605  13275   1292    198  11727     24    996   2605\n",
      "  28224    535   4257    198  12422     15    338   4751   4257    198\n",
      "  12422     16    415   2605   4257   2769  29579    198  12422     17\n",
      "    415  13072  30618  21640    198    678     25   7257   5121     11\n",
      "  17736     25    220  12422     18     11  13534     25   1665      6\n",
      "    311    264  51114    480   5375   2115     13 128000  20613   2115\n",
      "   4096     25    220     15   6794  33278    198     16   6794  33278\n",
      "    198     17    996   2944   2082    369    279  28174    198     18\n",
      "    996   2944   2082    369    279  28174    198     19    996   2944\n",
      "   2082    369    279  28174    198   3909   2564  27381  11727     23\n",
      "   7714  33278    198  11727     24   7714  33278    198  12422     15\n",
      "   7714  33278    198  12422     16   7714  33278    198  12422     17\n",
      "   7714  33278    198    678     25   7257  11229     11  17736     25\n",
      "    220  12422     18     11  13534     25   1665    198     38   5375\n",
      "   2115     25    220     15   1408   6969  20734   4813    198     16\n",
      "    338   6969  23326  49102   5441  73045  10225     62   2437    198\n",
      "     17    338   6969  23326  49102   5441  73045  10225     62   1721\n",
      "    198     18    338   6969  23326  49102   5441  73045  10225     62\n",
      "   2839    198     19    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2371    198   5218   2564  37677  11727     23    262  15643\n",
      "  63642  20739  55736  37372   4813    198  11727     24    310  15643\n",
      "  63642  20739  13343  19007    198  12422     15    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     16    415  15643  63642\n",
      "  20739  81002   3579  19007    198  12422     17   1835  15643  63642\n",
      "  49219  42103   1341  12121    198    678     25    342   3013   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "    198     38   5375   2115   4096     25    423 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009], True Label: [128000   2276    279   7257   2115    364     15   1733   2759    609\n",
      "    198     16    286  12751    355    479  39329   4229    198     17\n",
      "    996  28174  39329   4229    198     18    996  28174  39329   4229\n",
      "    198     19    996  28174  39329   4229    198    338   2564  16554\n",
      "  11727     23   1881   2605  13275   1292    198  11727     24    996\n",
      "   2605  28224    535   4257    198  12422     15    338   4751   4257\n",
      "    198  12422     16    415   2605   4257   2769  29579    198  12422\n",
      "     17    415  13072  30618  21640    198    678     25   7257   5121\n",
      "     11  17736     25    220  12422     18     11  13534     25   1665\n",
      "      6    311    264  51114    480   5375   2115     13 128000  20613\n",
      "   2115   4096     25    220     15   6794  33278    198     16   6794\n",
      "  33278    198     17    996   2944   2082    369    279  28174    198\n",
      "     18    996   2944   2082    369    279  28174    198     19    996\n",
      "   2944   2082    369    279  28174    198   3909   2564  27381  11727\n",
      "     23   7714  33278    198  11727     24   7714  33278    198  12422\n",
      "     15   7714  33278    198  12422     16   7714  33278    198  12422\n",
      "     17   7714  33278    198    678     25   7257  11229     11  17736\n",
      "     25    220  12422     18     11  13534     25   1665    198     38\n",
      "   5375   2115     25    220     15   1408   6969  20734   4813    198\n",
      "     16    338   6969  23326  49102   5441  73045  10225     62   2437\n",
      "    198     17    338   6969  23326  49102   5441  73045  10225     62\n",
      "   1721    198     18    338   6969  23326  49102   5441  73045  10225\n",
      "     62   2839    198     19    338   6969  23326  49102   5441  73045\n",
      "  10225     62   2371    198   5218   2564  37677  11727     23    262\n",
      "  15643  63642  20739  55736  37372   4813    198  11727     24    310\n",
      "  15643  63642  20739  13343  19007    198  12422     15    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     16    415  15643\n",
      "  63642  20739  81002   3579  19007    198  12422     17   1835  15643\n",
      "  63642  49219  42103   1341  12121    198    678     25    342   3013\n",
      "   5121     11  17736     25    220  12422     18     11  13534     25\n",
      "   1665    198     38   5375   2115   4096     25    423 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009 128009 128009 128009 128009 128009 128009 128009 128009\n",
      " 128009 128009]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "def predict_in_batches(test_dataset, batch_size=8):\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predicted_labels = logits.argmax(dim=-1)\n",
    "            \n",
    "            true_labels = batch.get('labels', None)\n",
    "            if true_labels is not None:\n",
    "                true_labels = true_labels\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            all_predictions.extend(predicted_labels.cpu().numpy())\n",
    "            if true_labels is not None:\n",
    "                all_true_labels.extend(true_labels.cpu().numpy())\n",
    "\n",
    "    return all_predictions, all_true_labels\n",
    "\n",
    "# Make predictions on the test set in smaller batches\n",
    "predicted_labels, true_labels = predict_in_batches(test_dataset, batch_size=4)\n",
    "\n",
    "# Print a few predictions vs. true labels\n",
    "for i in range(10):  # Display the first 10 samples\n",
    "    print(f\"Prediction: {predicted_labels[i]}, True Label: {true_labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8129444e-0966-4343-b521-f386514b1e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3984\n",
      "Precision: 0.0092\n",
      "Recall: 0.0093\n",
      "F1 Score: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Flatten the lists in case the predictions and true labels are 2D arrays\n",
    "predicted_labels_flat = [label for sublist in predicted_labels for label in sublist]\n",
    "true_labels_flat = [label for sublist in true_labels for label in sublist]\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(true_labels_flat, predicted_labels_flat)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate Precision, Recall, and F1 score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels_flat, predicted_labels_flat, average='macro')\n",
    "\n",
    "# You can also calculate these metrics per class by setting `average=None`\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34afdf78-ea65-44ec-a265-14e059282b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
